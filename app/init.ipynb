{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb1c25b",
   "metadata": {},
   "source": [
    "# ðŸ§  Collabris RAG Notebook (MVP)\n",
    "### Minimal schema + DB connection + Ollama API test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf13a666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('postgresql://postgres:postgres@localhost:5555/env-testing',\n",
       " 'http://localhost:11434',\n",
       " 'smollm:360m')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import psycopg\n",
    "from pgvector.psycopg import register_vector\n",
    "import requests\n",
    "import pandas as pd\n",
    "import ollama\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "## Database\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_DATABASE = os.getenv(\"DB_DATABASE\")\n",
    "DB_USERNAME = os.getenv(\"DB_USERNAME\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DATABASE_URL = f\"postgresql://{DB_USERNAME}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_DATABASE}\"\n",
    "\n",
    "##Olama\n",
    "OLLAMA_URL = os.getenv(\"OLLAMA_URL\", \"http://localhost:11434\")\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"smollm:360m\")\n",
    "\n",
    "client = ollama.Client(host=OLLAMA_URL)\n",
    "client.default_model = OLLAMA_MODEL\n",
    "\n",
    "DATABASE_URL, OLLAMA_URL, OLLAMA_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ec8743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to pgvector database.\n"
     ]
    }
   ],
   "source": [
    "def get_conn():\n",
    "    conn = psycopg.connect(DATABASE_URL)\n",
    "    register_vector(conn)\n",
    "    return conn\n",
    "\n",
    "try:\n",
    "    conn = get_conn()\n",
    "    print(\"Connected to pgvector database.\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\"DB connection error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7abcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Minimal schema created.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Minimal Viable Schema\n",
    "CREATE_DOCUMENTS = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS documents (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    title TEXT NOT NULL,\n",
    "    description TEXT,\n",
    "    source_type TEXT,\n",
    "    created_at TIMESTAMP DEFAULT NOW()\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "CREATE_CHUNKS = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS chunks (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,\n",
    "    chunk_index INTEGER NOT NULL,\n",
    "    content TEXT NOT NULL,\n",
    "    embedding VECTOR(768),\n",
    "    token_count INTEGER,\n",
    "    created_at TIMESTAMP DEFAULT NOW()\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "conn = get_conn()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(CREATE_DOCUMENTS)\n",
    "    cur.execute(CREATE_CHUNKS)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "\"Minimal schema created.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ace2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_generate(prompt: str, model: str = None):\n",
    "    model = model or OLLAMA_MODEL\n",
    "    try:\n",
    "        response = client.generate(\n",
    "            model=model,\n",
    "            prompt=prompt\n",
    "        )\n",
    "        return response.get(\"response\", \"\")\n",
    "    except Exception as e:\n",
    "        return f\"[Ollama Error] {str(e)}\"\n",
    "\n",
    "\n",
    "def ollama_embed(text: str, model: str = None):\n",
    "    model = model or OLLAMA_MODEL\n",
    "    try:\n",
    "        response = client.embeddings(\n",
    "            model=model,\n",
    "            prompt=text\n",
    "        )\n",
    "        return response.get(\"embedding\")\n",
    "    except Exception as e:\n",
    "        print(\"[Embedding Error]\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43cdae03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm happy to help! Jupyter Notebooks are a powerful tool for data science and education, and I'd be happy to explain how they work.\\n\\n**What is a Jupyter Notebook?**\\n\\nA Jupyter Notebook is an interactive environment that allows you to write, edit, and visualize code in real-time. It's similar to a spreadsheet but with some key differences:\\n\\n1. **Interactive code**: You can type code directly into the notebook, which runs on your computer or device.\\n2. **Visualization tools**: Jupyter Notebooks come with built-in visualization tools like plots, charts, and maps that allow you to explore data in a more intuitive way.\\n3. **Markdown syntax**: You can write Markdown code blocks, which are similar to HTML but use tags instead of square brackets.\\n4. **Rendering engine**: Jupyter Notebooks render their output on your computer's screen or send it directly to a web server for display.\\n\\n**How does a Jupyter Notebook work?**\\n\\nHere's a step-by-step explanation:\\n\\n1. You create a new notebook by running `jupyter nbconvert` in your terminal or command prompt.\\n2. The notebook is launched and you can start writing code, which runs on your computer or device.\\n3. When you're finished coding, you can save the changes to a file (e.g., `my_notebook.ipynb`) using `jupyter nbconvert` or by pressing `Ctrl+N`.\\n4. The notebook is rendered on your screen and displayed as an HTML page with Markdown code blocks.\\n5. You can interact with the notebook by clicking buttons, hovering over elements, or using keyboard shortcuts (e.g., Ctrl+Shift+F for a new cell).\\n6. Jupyter Notebooks support various visualization tools, such as plots, charts, and maps, which you can use to explore your data in more detail.\\n7. You can also export the notebook's output to a file or send it directly to a web server using `jupyter nbconvert` or other methods.\\n\\n**Benefits of Jupyter Notebooks**\\n\\n1. **Interactive learning**: Jupyter Notebooks allow you to experiment with different scenarios, data sets, and visualizations without having to write code from scratch.\\n2. **Collaboration**: Multiple users can work on the same notebook simultaneously, making it ideal for group projects or real-time collaboration.\\n3. **Data exploration**: Jupyter Notebooks provide an interactive environment for exploring data, which is essential in many fields like science, engineering, and business analysis.\\n4. **Version control**: Jupyter Notebooks track changes made to the notebook history, allowing you to easily revert to previous versions if needed.\\n5. **Extensive libraries and frameworks**: Jupyter Notebooks support a wide range of libraries and frameworks, including NumPy, pandas, scikit-learn, TensorFlow, and more.\\n\\nI hope this helps you understand how Jupyter Notebooks work!\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama_generate(\"Hello from Jupyter Notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325187d6",
   "metadata": {},
   "source": [
    "### RAG - Process Document\n",
    "Chunks, Embessings etc.\n",
    "! Not tested yet !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_document(title: str, description: str = None, source_type: str = None):\n",
    "    conn = get_conn()\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"INSERT INTO documents (title, description, source_type) VALUES (%s, %s, %s) RETURNING id\",\n",
    "            (title, description, source_type)\n",
    "        )\n",
    "        doc_id = cur.fetchone()[0]\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    return doc_id\n",
    "\n",
    "doc_id = add_document(\"Deep Learning Paper\", \"A paper about DL\", \"pdf\")\n",
    "doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bae595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_chunk(document_id: int, chunk_index: int, content: str):\n",
    "    embedding = ollama_embed(content)\n",
    "    token_count = len(content.split())\n",
    "\n",
    "    conn = get_conn()\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"INSERT INTO chunks (document_id, chunk_index, content, embedding, token_count) VALUES (%s, %s, %s, %s, %s)\",\n",
    "            (document_id, chunk_index, content, embedding, token_count)\n",
    "        )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "add_chunk(doc_id, 0, \"Deep learning has transformed scientific research.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2474a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query: str, limit: int = 3):\n",
    "    qvec = ollama_embed(query)\n",
    "    conn = get_conn()\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT content, embedding <-> %s AS distance\n",
    "            FROM chunks\n",
    "            ORDER BY embedding <-> %s\n",
    "            LIMIT %s\n",
    "            \"\"\",\n",
    "            (qvec, qvec, limit)\n",
    "        )\n",
    "        rows = cur.fetchall()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "search(\"What is deep learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0370cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(query: str):\n",
    "    results = search(query)\n",
    "    context = \"\\n\".join([row[0] for row in results])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    return ollama_generate(prompt)\n",
    "\n",
    "rag_answer(\"Explain deep learning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = get_conn()\n",
    "df = pd.read_sql(\"SELECT * FROM documents\", conn)\n",
    "conn.close()\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
